{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import jax.numpy as jnp\n",
    "import itertools\n",
    "\n",
    "\n",
    "def join_ct_suv(ct: sitk.Image, suv: sitk.Image,ct1: sitk.Image, suv1: sitk.Image) -> sitk.Image:\n",
    "    '\n",
    "    Resample a CT image to the same size as a SUV image\n",
    "    '\n",
    "   \n",
    "    ct_arr=sitk.GetArrayFromImage(ct)\n",
    "    suv_arr=sitk.GetArrayFromImage(suv)\n",
    "\n",
    "    ct_arr_1=sitk.GetArrayFromImage(ct1)\n",
    "    suv_arr_1=sitk.GetArrayFromImage(suv1)\n",
    "    \n",
    "    res=jnp.stack([jnp.array(suv_arr),jnp.array(ct_arr),jnp.array(ct_arr_1),jnp.array(suv_arr_1)],axis=-1)\n",
    "    return res\n",
    "\n",
    "def load_landmark_data(folder_path:str):\n",
    "    '\n",
    "    given path to folder with landmarks files and images after general registaration we load the data\n",
    "    we want to first load the suv and ct images resample them to the same size and then load the landmarks\n",
    "    we need to load separately study 0 and 1 \n",
    "    the output should be in form of a dictionary with keys 'study_0','study_1','From`,`To`' where `From` and `To` are the landmarks\n",
    "    all the data should be in form of jnp.arrays\n",
    "    '\n",
    "    ct_0=sitk.ReadImage(folder_path+'/study_0_ct_soft.nii.gz')\n",
    "    suv_0=sitk.ReadImage(folder_path+'/study_0_SUVS.nii.gz')\n",
    "    # Resample ct_0 to match ct_1\n",
    "            \n",
    "    ct_1=sitk.ReadImage(folder_path+'/study_1_ct_soft.nii.gz')\n",
    "    suv_1=sitk.ReadImage(folder_path+'/study_1_SUVS.nii.gz')    \n",
    "    arr_0 = join_ct_suv(ct_0, suv_0,ct_1, suv_1)\n",
    "\n",
    "    return {'study':arr_0, 'From':jnp.load(folder_path+'/From.npy'),'To':jnp.load(folder_path+'/To.npy')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "folder_path='/root/data/prepared_registered'\n",
    "# folder_path='/root/data/prepared_registered/pat_2/general_transform'\n",
    "# load_landmark_data(folder_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reshape_image(arr, img_size):\n",
    "    # Get the current shape of the input array\n",
    "    img_size=(img_size[1],img_size[2],img_size[3],img_size[4])\n",
    "    current_shape = arr.shape\n",
    "    \n",
    "    # Check if the current shape is already equal to the desired shape\n",
    "    if current_shape == img_size:\n",
    "        print(\"The input array already has the desired shape.\")\n",
    "        return arr\n",
    "    \n",
    "    # Check if the current shape is larger than the desired shape in any dimension\n",
    "    if any(cs > ds for cs, ds in zip(current_shape, img_size)):\n",
    "        # Crop the input array from the end of the dimension where it occurs\n",
    "        arr = arr[:img_size[0], :img_size[1], :img_size[2], :img_size[3]]\n",
    "        print(\"The input array has been cropped to the desired shape.\")\n",
    "    \n",
    "    # Check if the current shape is smaller than the desired shape in any dimension\n",
    "    if any(cs < ds for cs, ds in zip(current_shape, img_size)):\n",
    "        # Pad the input array with zeros at the end of the dimension where it occurs\n",
    "\n",
    "        arr = np.pad(arr, ((0, np.max(img_size[0] - current_shape[0],0)),\n",
    "                                  (0, np.max(img_size[1] - current_shape[1],0)),\n",
    "                                  (0, np.max(img_size[2] - current_shape[2],0)),\n",
    "                                  (0, 0)), mode='constant')\n",
    "        print(\"The input array has been padded to the desired shape.\")\n",
    "    \n",
    "    # If none of the above conditions are met, return the input array as is\n",
    "    return arr\n",
    "\n",
    "batch_size=2\n",
    "img_size = (batch_size,488, 200, 200,2)\n",
    "\n",
    "def stack_with_pad(arr_0,arr_1):\n",
    "    if arr_0.shape[0] > arr_1.shape[0]:\n",
    "        pad_length = arr_0.shape[0] - arr_1.shape[0]\n",
    "        padding = jnp.full((pad_length, arr_1.shape[1]), -1)\n",
    "        arr_1 = jnp.concatenate((arr_1, padding), axis=0)\n",
    "    elif arr_1.shape[0] > arr_0.shape[0]:\n",
    "        pad_length = arr_1.shape[0] - arr_0.shape[0]\n",
    "        padding = jnp.full((pad_length, arr_0.shape[1]), -1)\n",
    "        arr_0 = jnp.concatenate((arr_0, padding), axis=0)\n",
    "    \n",
    "    return jnp.stack([arr_0, arr_1])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_batched(folder_tuple):\n",
    "    folder_0=load_landmark_data(f\"{folder_tuple[0]}/general_transform\")\n",
    "    folder_1=load_landmark_data(f\"{folder_tuple[1]}/general_transform\")\n",
    "    arr=jnp.stack([reshape_image(folder_0['study'],img_size),reshape_image(folder_1['study'],img_size)])\n",
    "    From=stack_with_pad(folder_0['From'],folder_1['From'])\n",
    "    To=stack_with_pad(folder_0['To'],folder_1['To'])\n",
    "    return {'study':arr, 'From':From,'To':To}\n",
    "\n",
    "\n",
    "# folder_tuples = list(itertools.zip_longest(*[iter(folder_names)] * 2))\n",
    "# tt=list(map(get_batched,folder_tuples))\n",
    "\n",
    "# tt=list(map(lambda el: reshape_image(load_landmark_data(f\"{el}/general_transform\")['study'],img_size) ,folder_names))\n",
    "\n",
    "# create a function that given input array'arr' will change it shape to shape given as 'img_size' if the given image is bigger than 'img_size' in any dimension image should be cropped from the end of dimension where it happend in case when image is bigger than 'img_size' image should be padded with zeros at the end of dimension where it happens ; check weather the resulting image has shape required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pat_id', 'lesion_num', 'study_0_or_1', 'Deauville', 'lab_path',\n",
       "       'mod_name', 'vol_in_mm3', 'original_firstorder_10Percentile_pet',\n",
       "       'original_firstorder_90Percentile_pet',\n",
       "       'original_firstorder_Energy_pet',\n",
       "       ...\n",
       "       'wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis_ct',\n",
       "       'wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis_ct',\n",
       "       'wavelet-LLL_glszm_ZoneEntropy_ct',\n",
       "       'wavelet-LLL_glszm_ZonePercentage_ct',\n",
       "       'wavelet-LLL_glszm_ZoneVariance_ct', 'wavelet-LLL_ngtdm_Busyness_ct',\n",
       "       'wavelet-LLL_ngtdm_Coarseness_ct', 'wavelet-LLL_ngtdm_Complexity_ct',\n",
       "       'wavelet-LLL_ngtdm_Contrast_ct', 'wavelet-LLL_ngtdm_Strength_ct'],\n",
       "      dtype='object', length=2425)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "radiomics_full_data_path=\"/workspaces/pilot_lymphoma/data/extracted_features_pet_full_curr.csv\"\n",
    "radiomics_full_data=pd.read_csv(radiomics_full_data_path)\n",
    "radiomics_full_data = radiomics_full_data.loc[:, ~radiomics_full_data.columns.str.contains('Unnamed', case=False)]\n",
    "radiomics_full_data = radiomics_full_data[radiomics_full_data['lesion_num'] == 1000]\n",
    "radiomics_full_data[\"pat_id\"]=radiomics_full_data[\"pat_id\"].astype(int)\n",
    "radiomics_full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<bound method IndexOpsMixin.to_numpy of 0     PR\n",
       "       1     CR\n",
       "       2     PR\n",
       "       3     CR\n",
       "       4     PD\n",
       "       5     CR\n",
       "       6     CR\n",
       "       7     SD\n",
       "       8     CR\n",
       "       9     CR\n",
       "       10    PD\n",
       "       11    PD\n",
       "       12    PR\n",
       "       13    PD\n",
       "       14    PR\n",
       "       15    SD\n",
       "       16    CR\n",
       "       17    CR\n",
       "       18    CR\n",
       "       19    CR\n",
       "       20    CR\n",
       "       21    CR\n",
       "       22    SD\n",
       "       23    PD\n",
       "       24    CR\n",
       "       25    PD\n",
       "       26    CR\n",
       "       27    CR\n",
       "       28    PD\n",
       "       29    CR\n",
       "       30    CR\n",
       "       31    PR\n",
       "       Name: outcome, dtype: object>                   ], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_table_path=\"/workspaces/pilot_lymphoma/data/full_table_data_for_delta.csv\"\n",
    "full_data_table= pd.read_csv(full_data_table_path)\n",
    "full_data_table[\"pat_id\"]=full_data_table[\"Unnamed: 0\"].astype(int)\n",
    "full_data_table[\"outcome\"]=full_data_table[\"Unnamed: 12\"]\n",
    "np.unique(full_data_table[\"outcome\"].to_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m     38\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(full_data_table\u001b[38;5;241m.\u001b[39miterrows())\n\u001b[0;32m---> 41\u001b[0m \u001b[43mget_delta_radiomics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiomics_full_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 29\u001b[0m, in \u001b[0;36mget_delta_radiomics\u001b[0;34m(full_data_table_row, radiomics_full_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Step 4\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m res \u001b[38;5;241m=\u001b[39m subtract_dicts(rows\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict(),\u001b[43mrows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_dict(),row_sum )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Step 5\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "\n",
    "def subtract_dicts(dict1, dict2,dict_sums):\n",
    "    # Create a new dictionary with the absolute difference of each entry\n",
    "    result = {key: abs(dict1[key] - dict2[key])/dict_sums[key] for key in dict1}\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_delta_radiomics(full_data_table_row, radiomics_full_data):\n",
    "\n",
    "    \"\"\"a function 'get_delta_radiomics' that would have two arguments 'full_data_table_row' and 'radiomics_full_data'.  'full_data_table_row' is a row from main table and contains columns like '[pat_id,outcome]'   'radiomics_full_data' contains multiple column including'[pat_id,study_0_or_1]'  Function should perform all steps:\n",
    "    1) find 2 rows from 'radiomics_full_data' where  value of column 'pat_id' would be the same as value of column 'pat_id' in 'full_data_table_row' \n",
    "    2) From those 2 rows you found drop columns with names: ```['pat_id', 'lesion_num', 'study_0_or_1', 'Deauville', 'lab_path', 'mod_name']```\n",
    "    3) Save the sum of both rows so each column should have sum of 2 rows\n",
    "    4) calculate the absolute value of the diffrence between two rows and divide it by the saved sum save information as dictionary called 'res'\n",
    "    5) add outcome variable to 'res' that you will find in column 'outcome' in 'full_data_table_row' encode the  'outcome' as integer as in the dictionary {'CR':0, 'PD':1, 'PR':2, 'SD':2, }\n",
    "    6) return calculated dictionary res\"\"\"\n",
    "    full_data_table_row=full_data_table_row[1]\n",
    "    # print(f\"pppp {full_data_table_row['pat_id']}\")\n",
    "    # Step 1\n",
    "    rows = radiomics_full_data[radiomics_full_data['pat_id'] == full_data_table_row['pat_id']]\n",
    "    \n",
    "    # Step 2\n",
    "    rows = rows.drop(columns=['pat_id', 'lesion_num', 'study_0_or_1', 'Deauville', 'lab_path', 'mod_name'])\n",
    "    # Step 3\n",
    "    row_sum = rows.sum().to_dict()\n",
    "   \n",
    "    print(len(rows))\n",
    "    # Step 4\n",
    "    res = subtract_dicts(rows.iloc[0].to_dict(),rows.iloc[1].to_dict(),row_sum )\n",
    "    print(res)\n",
    "    # Step 5\n",
    "    outcome_dict = {'CR':0, 'PD':1, 'PR':2, 'SD':2}\n",
    "    res['outcome'] = outcome_dict[full_data_table_row['outcome']]\n",
    "\n",
    "    # Step 6\n",
    "    return res\n",
    "\n",
    "rows = list(full_data_table.iterrows())\n",
    "\n",
    "\n",
    "get_delta_radiomics(rows[2], radiomics_full_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what is the sum of euclidean distances for diffrent registrations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/data/prepared_registered/pat_12',\n",
       " '/root/data/prepared_registered/pat_16',\n",
       " '/root/data/prepared_registered/pat_31',\n",
       " '/root/data/prepared_registered/pat_21',\n",
       " '/root/data/prepared_registered/pat_26',\n",
       " '/root/data/prepared_registered/pat_2',\n",
       " '/root/data/prepared_registered/pat_19',\n",
       " '/root/data/prepared_registered/pat_13',\n",
       " '/root/data/prepared_registered/pat_10',\n",
       " '/root/data/prepared_registered/pat_28',\n",
       " '/root/data/prepared_registered/pat_8',\n",
       " '/root/data/prepared_registered/pat_24',\n",
       " '/root/data/prepared_registered/pat_15',\n",
       " '/root/data/prepared_registered/pat_4',\n",
       " '/root/data/prepared_registered/pat_29',\n",
       " '/root/data/prepared_registered/pat_14',\n",
       " '/root/data/prepared_registered/pat_20',\n",
       " '/root/data/prepared_registered/pat_22',\n",
       " '/root/data/prepared_registered/pat_5',\n",
       " '/root/data/prepared_registered/pat_18',\n",
       " '/root/data/prepared_registered/pat_11',\n",
       " '/root/data/prepared_registered/pat_9',\n",
       " '/root/data/prepared_registered/pat_27',\n",
       " '/root/data/prepared_registered/pat_3',\n",
       " '/root/data/prepared_registered/pat_23',\n",
       " '/root/data/prepared_registered/pat_7',\n",
       " '/root/data/prepared_registered/pat_25',\n",
       " '/root/data/prepared_registered/pat_6']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_names = [os.path.join(folder_path, name) for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "folder_names= list(filter(lambda el: \"pat\" in el, folder_names))\n",
    "folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.419910917593374"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking from linear folder the distance\n",
    "def get_dist_0(fold_name):\n",
    "  fold=f\"{fold_name}/lin_transf\"\n",
    "  fromm=np.load(f\"{fold}/From.npy\")\n",
    "  too=np.load(f\"{fold}/To.npy\")\n",
    "\n",
    "  res=(fromm-too)\n",
    "  res=res*(fromm>0)\n",
    "  res=np.sqrt(np.sum(res**2,axis=-1))\n",
    "  return np.sum(res.flatten())\n",
    "\n",
    "np.mean(list(map(get_dist_0,folder_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
