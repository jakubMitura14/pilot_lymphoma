{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[2., 2., 2.],\n",
       "       [2., 1., 2.],\n",
       "       [2., 3., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adapted from https://stackoverflow.com/questions/74519927/best-way-to-rotate-and-translate-a-set-of-points-in-python\n",
    "\n",
    "def rotate_and_translate(points: jnp.ndarray\n",
    "                         , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                         translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "    rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "    return (points - center_point) @ rotation_matrix.T + center_point + translation_vector\n",
    "\n",
    "\n",
    "\n",
    "# rotateMatrix = Rotation.from_rotvec(jnp.array([ jnp.pi,0.0, 0.0])).as_matrix()\n",
    "points=jnp.array([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, -1.0, 0.0]])\n",
    "center_point=jnp.array([0.0, 0.0, 0.0])\n",
    "# newxy = (points-center_point) @ rotateMatrix.T + center_point\n",
    "\n",
    "newxy=rotate_and_translate(points, center_point, jnp.array([ jnp.pi,0.0, 0.0]), jnp.array([2.0, 2.0, 2.0]))\n",
    "newxy.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=jnp.array([1.0, 1.0, 1.0,2.0, 2.0, 2.0,3.0, 3.0, 3.0])\n",
    "weights[0:3]\n",
    "weights[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "\n",
    "\n",
    "def rotate_and_translate(points: jnp.ndarray\n",
    "                         , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                         translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "    rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "    return (points - center_point) @ rotation_matrix.T + center_point + translation_vector\n",
    "\n",
    "\n",
    "def get_fiducial_loos(weights,from_landmarsk,to_landmarks,image_shape):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "        0-3 first rotation vector   \n",
    "        3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation\n",
    "    we apply this transformation to the fiducial points of moving image and \n",
    "    calculate the square distance between transformed fiducial points and fiducial points on fixed image           \n",
    "    \"\"\"\n",
    "    center_point=(jnp.asarray(image_shape) - 1.) / 2\n",
    "    res=rotate_and_translate(to_landmarks, center_point, weights[0:3],weights[3:6])\n",
    "    #calculate the square distance between transformed fiducial points and fiducial points on fixed image \n",
    "    return jnp.sum(((from_landmarsk-res)**2).flatten())\n",
    "    \n",
    "    \n",
    "def transform_image(image,weights):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "    0-3 first rotation vector   \n",
    "    3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation;rotation\n",
    "    \n",
    "    \"\"\"    \n",
    "    r = Rotation.from_rotvec(weights[0:3])\n",
    "    image=r.apply(image)\n",
    "    image=jax.image.scale_and_translate(image, image.shape,jnp.array([0,1,2]), jnp.array([1.0,1.0,1.0]), weights[3:6], \"bicubic\")\n",
    "    return image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_0': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'study_1': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'From': Array([[   -9.490384 ,   201.9817   ,  -434.5      ],\n",
       "        [  -10.825081 ,   223.7493   ,  -537.2692   ],\n",
       "        [   -2.6794205,   136.67894  ,  -907.3182   ],\n",
       "        [  -42.204777 ,   143.36389  , -1004.6995   ],\n",
       "        [   49.448223 ,   139.29106  , -1010.4278   ]], dtype=float32),\n",
       " 'To': Array([[-1.5628610e+01,  2.2513477e+02, -1.0745000e+03],\n",
       "        [-1.2932510e+01,  2.3373933e+02, -1.2070104e+03],\n",
       "        [-7.1401978e-01,  1.3851543e+02, -1.5706969e+03],\n",
       "        [-3.9721409e+01,  1.5480675e+02, -1.6590372e+03],\n",
       "        [ 4.5177025e+01,  1.5073392e+02, -1.6750990e+03]], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def resample_ct_to_suv(ct: sitk.Image, suv: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Resample a CT image to the same size as a SUV image\n",
    "    \"\"\"\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "    resampler.SetOutputSpacing(suv.GetSpacing())\n",
    "    resampler.SetSize(suv.GetSize())\n",
    "    resampler.SetOutputDirection(suv.GetDirection())\n",
    "    resampler.SetOutputOrigin(suv.GetOrigin())\n",
    "    ct= resampler.Execute(ct)\n",
    "    \n",
    "    ct_arr=sitk.GetArrayFromImage(ct)\n",
    "    suv_arr=sitk.GetArrayFromImage(suv)\n",
    "    \n",
    "    res=jnp.stack([jnp.array(suv_arr),jnp.array(ct_arr)],axis=0)\n",
    "    return res\n",
    "\n",
    "def load_landmark_data(folder_path:str):\n",
    "    \"\"\"\n",
    "    given path to folder with landmarks files and images after general registaration we load the data\n",
    "    we want to first load the suv and ct images resample them to the same size and then load the landmarks\n",
    "    we need to load separately study 0 and 1 \n",
    "    the output should be in form of a dictionary with keys 'study_0','study_1','From`,`To`' where `From` and `To` are the landmarks\n",
    "    all the data should be in form of jnp.arrays\n",
    "    \"\"\"\n",
    "    ct_0=sitk.ReadImage(folder_path+'/study_0_ct_soft.nii.gz')\n",
    "    suv_0=sitk.ReadImage(folder_path+'/study_0_SUVS.nii.gz')\n",
    "    # Resample ct_0 to match ct_1\n",
    "    arr_0 = resample_ct_to_suv(ct_0, suv_0)\n",
    "            \n",
    "    ct_1=sitk.ReadImage(folder_path+'/study_1_ct_soft.nii.gz')\n",
    "    suv_1=sitk.ReadImage(folder_path+'/study_1_SUVS.nii.gz')    \n",
    "    arr_1 = resample_ct_to_suv(ct_1, suv_1)\n",
    "\n",
    "    return {'study_0':arr_0,'study_1':arr_1, 'From':jnp.load(folder_path+'/From.npy'),'To':jnp.load(folder_path+'/To.npy')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path='/root/data/pat_2/general_transform'\n",
    "load_landmark_data(folder_path)\n",
    "\n",
    "# cp /root/data/pat_2/To.npy /root/data/pat_2/general_transform/To.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/data/pat_9/general_transform', '/root/data/pat_20/general_transform', '/root/data/pat_18/general_transform', '/root/data/pat_12/general_transform', '/root/data/pat_31/general_transform', '/root/data/pat_24/general_transform', '/root/data/pat_4/general_transform', '/root/data/pat_11/general_transform', '/root/data/pat_28/general_transform', '/root/data/pat_25/general_transform', '/root/data/pat_29/general_transform', '/root/data/pat_15/general_transform', '/root/data/pat_14/general_transform', '/root/data/pat_5/general_transform', '/root/data/pat_27/general_transform', '/root/data/pat_22/general_transform', '/root/data/pat_21/general_transform', '/root/data/pat_3/general_transform', '/root/data/pat_10/general_transform', '/root/data/pat_23/general_transform', '/root/data/pat_8/general_transform', '/root/data/pat_6/general_transform', '/root/data/pat_13/general_transform', '/root/data/pat_7/general_transform', '/root/data/pat_19/general_transform', '/root/data/pat_16/general_transform', '/root/data/pat_26/general_transform', '/root/data/pat_2/general_transform']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "folder_path = \"/root/data\"\n",
    "folder_names = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "folder_names=list(filter(lambda x: re.match(r'pat_\\d+',x),folder_names))\n",
    "folder_names=list(map(lambda x: f\"{folder_path}/{x}/general_transform\",folder_names))\n",
    "\n",
    "curr_folder='/root/data/pat_2/general_transform'\n",
    "data_dict=load_landmark_data(curr_folder)\n",
    "\n",
    "def get_data_for_pretained_model(image_dat,landmark_data, rng):\n",
    "    \"\"\"\n",
    "    given the image data and landmark data we return the data in the format that can be used for the pretrained model\n",
    "    so we make a random transformation of the image and the landmarks and return the transformed image and landmarks \n",
    "    \"\"\"\n",
    "\n",
    "    #random weights for the transformation\n",
    "    weights = jax.random.uniform(rng, shape=(6,), minval=0, maxval=300)\n",
    "\n",
    "    \n",
    "    transform_image(image_dat,weights)\n",
    "\n",
    "    rotate_and_translate(points: jnp.ndarray\n",
    "                            , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                            translation_vector: jnp.ndarray)\n",
    "\n",
    "\n",
    "    return data_dict['study_0'],data_dict['study_1'],data_dict['From'],data_dict['To']\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[[ 0.        ,  0.99999964,  2.0000002 ],\n",
       "        [ 3.        ,  3.999999  ,  5.0000005 ],\n",
       "        [ 6.        ,  6.9999986 ,  8.000001  ]],\n",
       "\n",
       "       [[ 9.        ,  9.999998  , 11.000002  ],\n",
       "        [12.        , 12.999997  , 14.000002  ],\n",
       "        [15.        , 15.999997  , 17.000002  ]],\n",
       "\n",
       "       [[18.        , 18.999996  , 20.000004  ],\n",
       "        [21.        , 21.999996  , 23.000004  ],\n",
       "        [24.        , 24.999996  , 26.000004  ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Rotation.from_rotvec(jnp.array([2*jnp.pi, 0.0, 0.0])) ####### it is in radians\n",
    "# imagee= jnp.zeros((3,3,3))\n",
    "\n",
    "# Create consecutive array of integers\n",
    "imagee = jnp.arange(27)\n",
    "imagee = imagee.reshape((3, 3, 3))\n",
    "\n",
    "print(imagee)\n",
    "imagee=r.apply(imagee)\n",
    "# imagee=jax.image.scale_and_translate(imagee, imagee.shape,jnp.array([0,1,2]), jnp.array([1.0,1.0,1.0]), jnp.array([0.1,0.0,0.0]), \"bicubic\")\n",
    "imagee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
