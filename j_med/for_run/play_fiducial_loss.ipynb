{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "from jax.scipy.spatial.transform import Rotation, Slerp\n",
    "import jax.numpy as jnp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#adapted from https://stackoverflow.com/questions/74519927/best-way-to-rotate-and-translate-a-set-of-points-in-python\n",
    "\n",
    "# def rotate_and_translate(points: jnp.ndarray\n",
    "#                          , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "#                          translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "#     # rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "#     rotation_matrix =Rotation.from_euler('xyz', rotation_vector, degrees=False).as_matrix()\n",
    "#     return (points - center_point) @ rotation_matrix.T + center_point + translation_vector\n",
    "\n",
    "\n",
    "\n",
    "# # rotateMatrix = Rotation.from_rotvec(jnp.array([ jnp.pi,0.0, 0.0])).as_matrix()\n",
    "# points=jnp.array([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, -1.0, 0.0]])\n",
    "# center_point=jnp.array([0.0, 0.0, 0.0])\n",
    "# # newxy = (points-center_point) @ rotateMatrix.T + center_point\n",
    "\n",
    "# newxy=rotate_and_translate(points, center_point, jnp.array([ jnp.pi,0.0, 0.0]), jnp.array([2.0, 2.0, 2.0]))\n",
    "# newxy.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=jnp.array([1.0, 1.0, 1.0,2.0, 2.0, 2.0,3.0, 3.0, 3.0])\n",
    "weights[0:3]\n",
    "weights[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "import chex\n",
    "from typing import Callable, Sequence, Tuple, Union\n",
    "from dm_pix._src import augment\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "def rotate_and_translate(points: jnp.ndarray\n",
    "                         , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                         translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "    # rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "\n",
    "    rotation_matrix =Rotation.from_euler('xyz', rotation_vector, degrees=True).inv().as_matrix()\n",
    "    return (points - center_point) @ rotation_matrix.T + center_point # + translation_vector #krowa TODO\n",
    "\n",
    "\n",
    "def get_fiducial_loos(weights,from_landmarsk,to_landmarks,image_shape):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "        0-3 first rotation vector   \n",
    "        3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation\n",
    "    we apply this transformation to the fiducial points of moving image and \n",
    "    calculate the square distance between transformed fiducial points and fiducial points on fixed image           \n",
    "    \"\"\"\n",
    "    center_point=(jnp.asarray(image_shape) - 1.) / 2\n",
    "    res=rotate_and_translate(to_landmarks, center_point, weights[0:3],weights[3:6])\n",
    "    #calculate the square distance between transformed fiducial points and fiducial points on fixed image \n",
    "    return jnp.sum(((from_landmarsk-res)**2).flatten())\n",
    "    \n",
    "\n",
    "# def affine_transform(\n",
    "#     image: chex.Array,\n",
    "#     matrix: chex.Array,\n",
    "#     *,\n",
    "#     offset: Union[chex.Array, chex.Numeric] = 0.,\n",
    "#     order: int = 1,\n",
    "#     mode: str = \"constant\",\n",
    "#     cval: float = 0.0,\n",
    "# ) -> chex.Array:\n",
    "#   \"\"\"Applies an affine transformation given by matrix.\n",
    "\n",
    "#   \"\"\"\n",
    "\n",
    "#   meshgrid = jnp.meshgrid(*[jnp.arange(size) for size in image.shape],\n",
    "#                           indexing=\"ij\")\n",
    "#   indices = jnp.concatenate(\n",
    "#       [jnp.expand_dims(x, axis=-1) for x in meshgrid], axis=-1)\n",
    "\n",
    "#   zz, yy, xx = meshgrid\n",
    "#   z_center, y_center,x_center= (jnp.asarray(image.shape) - 1.) / 2.\n",
    "#   indices = jnp.array([xx - x_center, yy - y_center, zz - z_center])\n",
    "\n",
    "#   coordinates = jnp.tensordot(matrix, indices, axes=((1), (0)))\n",
    "\n",
    "#   interpolate_function = augment._get_interpolate_function(\n",
    "#       mode=mode,\n",
    "#       order=order,\n",
    "#       cval=cval,\n",
    "#   )\n",
    "#   return interpolate_function(image, coordinates)\n",
    "\n",
    "\n",
    "    \n",
    "def transform_image(image,weights):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "    0-3 first rotation vector   \n",
    "    3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation;rotation\n",
    "    \"\"\"      \n",
    "    quaternion=np.array(Rotation.from_euler('xyz', weights[0:3], degrees=True).as_quat())\n",
    "    # image_path=\"/root/data/pat_2/general_transform//study_0_ct_soft.nii.gz\"\n",
    "    # image_path_b=\"/workspaces/pilot_lymphoma/data/rotated.nii.gz\"\n",
    "\n",
    "\n",
    "    # Load the image\n",
    "    image = sitk.GetImageFromArray(image)\n",
    "\n",
    "    # Get the center of the image\n",
    "    center = image.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in image.GetSize()])\n",
    "\n",
    "    # Create a VersorRigid3DTransform\n",
    "    transform = sitk.VersorRigid3DTransform()\n",
    "    transform.SetCenter(center)\n",
    "    transform.SetRotation([float(quaternion[0]),float(quaternion[1]),float(quaternion[2]),float(quaternion[3])])\n",
    "\n",
    "    # Resample the image\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputDirection(image.GetDirection())\n",
    "    resampler.SetOutputOrigin(image.GetOrigin())\n",
    "    resampler.SetOutputSpacing(image.GetSpacing())\n",
    "    resampler.SetSize(image.GetSize())\n",
    "    resampler.SetTransform(transform)\n",
    "\n",
    "    resampled_image = resampler.Execute(image)\n",
    "    res=sitk.GetArrayFromImage(resampled_image)\n",
    "    # image=affine_transform(image,Rotation.from_euler('xyz', weights[0:3], degrees=True).inv().as_matrix())\n",
    "    image=jnp.array(res)\n",
    "    res=jax.image.scale_and_translate(image, image.shape,jnp.array([0,1,2]), jnp.array([1.0,1.0,1.0]), (weights[3:6]/20), \"bicubic\")\n",
    "    return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_0': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'study_1': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'From': Array([[   -9.490384 ,   201.9817   ,  -434.5      ],\n",
       "        [  -10.825081 ,   223.7493   ,  -537.2692   ],\n",
       "        [   -2.6794205,   136.67894  ,  -907.3182   ],\n",
       "        [  -42.204777 ,   143.36389  , -1004.6995   ],\n",
       "        [   49.448223 ,   139.29106  , -1010.4278   ]], dtype=float32),\n",
       " 'To': Array([[-1.5628610e+01,  2.2513477e+02, -1.0745000e+03],\n",
       "        [-1.2932510e+01,  2.3373933e+02, -1.2070104e+03],\n",
       "        [-7.1401978e-01,  1.3851543e+02, -1.5706969e+03],\n",
       "        [-3.9721409e+01,  1.5480675e+02, -1.6590372e+03],\n",
       "        [ 4.5177025e+01,  1.5073392e+02, -1.6750990e+03]], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def resample_ct_to_suv(ct: sitk.Image, suv: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Resample a CT image to the same size as a SUV image\n",
    "    \"\"\"\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "    resampler.SetOutputSpacing(suv.GetSpacing())\n",
    "    resampler.SetSize(suv.GetSize())\n",
    "    resampler.SetOutputDirection(suv.GetDirection())\n",
    "    resampler.SetOutputOrigin(suv.GetOrigin())\n",
    "    ct= resampler.Execute(ct)\n",
    "    \n",
    "    ct_arr=sitk.GetArrayFromImage(ct)\n",
    "    suv_arr=sitk.GetArrayFromImage(suv)\n",
    "    \n",
    "    res=jnp.stack([jnp.array(suv_arr),jnp.array(ct_arr)],axis=0)\n",
    "    return res\n",
    "\n",
    "def load_landmark_data(folder_path:str):\n",
    "    \"\"\"\n",
    "    given path to folder with landmarks files and images after general registaration we load the data\n",
    "    we want to first load the suv and ct images resample them to the same size and then load the landmarks\n",
    "    we need to load separately study 0 and 1 \n",
    "    the output should be in form of a dictionary with keys 'study_0','study_1','From`,`To`' where `From` and `To` are the landmarks\n",
    "    all the data should be in form of jnp.arrays\n",
    "    \"\"\"\n",
    "    ct_0=sitk.ReadImage(folder_path+'/study_0_ct_soft.nii.gz')\n",
    "    suv_0=sitk.ReadImage(folder_path+'/study_0_SUVS.nii.gz')\n",
    "    # Resample ct_0 to match ct_1\n",
    "    arr_0 = resample_ct_to_suv(ct_0, suv_0)\n",
    "            \n",
    "    ct_1=sitk.ReadImage(folder_path+'/study_1_ct_soft.nii.gz')\n",
    "    suv_1=sitk.ReadImage(folder_path+'/study_1_SUVS.nii.gz')    \n",
    "    arr_1 = resample_ct_to_suv(ct_1, suv_1)\n",
    "\n",
    "    return {'study_0':arr_0,'study_1':arr_1, 'From':jnp.load(folder_path+'/From.npy'),'To':jnp.load(folder_path+'/To.npy')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path='/root/data/pat_2/general_transform'\n",
    "load_landmark_data(folder_path)\n",
    "\n",
    "# cp /root/data/pat_2/To.npy /root/data/pat_2/general_transform/To.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52336/2133640619.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52336/1815328740.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0mct_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/study_0_ct_soft.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msuv_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/study_0_SUVS.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Resample ct_0 to match ct_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0marr_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_ct_to_suv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuv_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mct_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/study_1_ct_soft.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msuv_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/study_1_SUVS.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_52336/1815328740.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(ct, suv)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputSpacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSpacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputDirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputOrigin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetOrigin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mct\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mct_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msuv_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, image1)\u001b[0m\n\u001b[1;32m  49588\u001b[0m         \u001b[0mExecute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  49589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  49590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  49591\u001b[0m         \"\"\"\n\u001b[0;32m> 49592\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResampleImageFilter_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "folder_path = \"/root/data\"\n",
    "folder_names = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "folder_names=list(filter(lambda x: re.match(r'pat_\\d+',x),folder_names))\n",
    "folder_names=list(map(lambda x: f\"{folder_path}/{x}/general_transform\",folder_names))\n",
    "\n",
    "curr_folder='/root/data/pat_2/general_transform'\n",
    "data_dict=load_landmark_data(curr_folder)\n",
    "\n",
    "# v_transform_image=jax.vmap(transform_image , in_axes = (0,None) )\n",
    "\n",
    "def get_data_for_pretained_model(image_dat,landmark_data, rng):\n",
    "    \"\"\"\n",
    "    given the image data and landmark data we return the data in the format that can be used for the pretrained model\n",
    "    so we make a random transformation of the image and the landmarks and return the transformed image and landmarks \n",
    "    \"\"\"\n",
    "    #random weights for the transformation\n",
    "    weights = jax.random.uniform(rng, shape=(6,), minval=0, maxval=360)\n",
    "    # weights = jnp.zeros((6,))#krowa\n",
    "    \n",
    "    # print(f\"image_dat {image_dat.shape} landmark_data {landmark_data.shape} weights {weights.shape}\")\n",
    "    tansf_image=jnp.stack([transform_image(image_dat[0,:,:,:],weights),transform_image(image_dat[1,:,:,:],weights)   ])\n",
    "    center_point=(jnp.asarray(image_dat.shape) - 1.) / 2\n",
    "    center_point=center_point[0:3]\n",
    "    # print(f\" landmark_data {landmark_data.shape} center_point {center_point} weights {weights.shape}\")\n",
    "    transf_landmarsk=rotate_and_translate(landmark_data, center_point,weights[0:3],(weights[3:6]/10))\n",
    "\n",
    "\n",
    "    return tansf_image,transf_landmarsk\n",
    "\n",
    "# krowa transform the image save it and check if it tranforms correctly\n",
    " \n",
    "\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "tansf_image,transf_landmarsk=get_data_for_pretained_model(data_dict['study_0'],data_dict['From'], rng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "out_folder_path=\"/workspaces/pilot_lymphoma/data\"\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `transf_image` and `data_dict['study_0']` are JAX arrays\n",
    "transf_image_np = np.array(tansf_image[0,:,:,:])\n",
    "study_0_np = np.array(data_dict['study_0'][0,:,:,:])\n",
    "\n",
    "# Create SimpleITK images\n",
    "transf_image_sitk = sitk.GetImageFromArray(transf_image_np)\n",
    "study_0_sitk = sitk.GetImageFromArray(study_0_np)\n",
    "\n",
    "# Save as NIfTI files\n",
    "sitk.WriteImage(transf_image_sitk, '/workspaces/pilot_lymphoma/data/transf_image.nii.gz')\n",
    "sitk.WriteImage(study_0_sitk, '/workspaces/pilot_lymphoma/data/study_0.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# def transform_image_sitk(image,weights):\n",
    "#     \"\"\"\n",
    "#     first entries in in weights are :\n",
    "#     0-3 first rotation vector   \n",
    "#     3-6 translation vector   \n",
    "#     so we interpret the weights as input for transormations rotation;translation;rotation\n",
    "#     \"\"\"      \n",
    "#     quaternion=np.array(Rotation.from_euler('xyz', weights[0:3], degrees=True).as_quat())\n",
    "#     # image_path=\"/root/data/pat_2/general_transform//study_0_ct_soft.nii.gz\"\n",
    "#     # image_path_b=\"/workspaces/pilot_lymphoma/data/rotated.nii.gz\"\n",
    "\n",
    "\n",
    "#     # Load the image\n",
    "#     # image = sitk.GetImageFromArray(image)\n",
    "\n",
    "#     # Get the center of the image\n",
    "#     center = image.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in image.GetSize()])\n",
    "\n",
    "#     # Create a VersorRigid3DTransform\n",
    "#     transform = sitk.VersorRigid3DTransform()\n",
    "#     transform.SetCenter(center)\n",
    "#     transform.SetRotation([float(quaternion[0]),float(quaternion[1]),float(quaternion[2]),float(quaternion[3])])\n",
    "\n",
    "#     # Resample the image\n",
    "#     resampler = sitk.ResampleImageFilter()\n",
    "#     resampler.SetOutputDirection(image.GetDirection())\n",
    "#     resampler.SetOutputOrigin(image.GetOrigin())\n",
    "#     resampler.SetOutputSpacing(image.GetSpacing())\n",
    "#     resampler.SetSize(image.GetSize())\n",
    "#     resampler.SetTransform(transform)\n",
    "\n",
    "#     resampled_image = resampler.Execute(image)\n",
    "#     # res=sitk.GetArrayFromImage(resampled_image)\n",
    "#     # # image=affine_transform(image,Rotation.from_euler('xyz', weights[0:3], degrees=True).inv().as_matrix())\n",
    "#     # image=jnp.array(res)\n",
    "#     # res=jax.image.scale_and_translate(image, image.shape,jnp.array([0,1,2]), jnp.array([1.0,1.0,1.0]), (weights[3:6]/20), \"bicubic\")\n",
    "#     return resampled_image\n",
    "\n",
    "# def rotate_point(point,transform):\n",
    "#     \"\"\"\n",
    "#     rotate a point using the transform\n",
    "#     \"\"\"\n",
    "#     # print(f\"point {point} \")\n",
    "#     return transform.TransformPoint(np.array(point).astype(float))\n",
    "    \n",
    "# def transform_points_sitk(landmark_data,center,weights):\n",
    "#     # Define your points and center\n",
    "#     # point1 = np.array([1.0, 1.0, 1.0])  # replace with your actual point\n",
    "#     # point2 = np.array([-1.0, -1.0, -1.0])  # replace with your actual point\n",
    "#     # center = np.array([0.0, 0.0, 0.0])  # replace with your actual center\n",
    "\n",
    "#     # Create an affine transform\n",
    "#     transform = sitk.AffineTransform(3)\n",
    "\n",
    "#     # Set the center of the transform\n",
    "#     transform.SetCenter(center)\n",
    "\n",
    "#     # Rotate the transform by 30 degrees around each axis\n",
    "#     # angle = math.radians(0)  # convert degrees to radians\n",
    "#     transform.Rotate(axis1=0, axis2=1, angle=math.radians(weights[0]))  # x-axis\n",
    "#     transform.Rotate(axis1=1, axis2=2, angle=math.radians(weights[1]))  # y-axis\n",
    "#     transform.Rotate(axis1=0, axis2=2, angle=math.radians(weights[2]))  # z-axis\n",
    "\n",
    "#     # Now you can use the transform to rotate your points\n",
    "    \n",
    "#     return list(map(lambda point: rotate_point(point,transform),landmark_data  ))\n",
    "\n",
    "    \n",
    "# def numpy_rotate_point(point, center, angles):\n",
    "\n",
    "#     # Convert angles from degrees to radians\n",
    "#     angles = np.radians(angles)\n",
    "\n",
    "#     # Translate point back to origin\n",
    "#     point -= center\n",
    "\n",
    "#     # Rotation matrix\n",
    "#     R_x = np.array([[1, 0, 0],\n",
    "#                     [0, np.cos(angles[0]), -np.sin(angles[0])],\n",
    "#                     [0, np.sin(angles[0]), np.cos(angles[0])]])\n",
    "\n",
    "#     R_y = np.array([[np.cos(angles[1]), 0, np.sin(angles[1])],\n",
    "#                     [0, 1, 0],\n",
    "#                     [-np.sin(angles[1]), 0, np.cos(angles[1])]])\n",
    "\n",
    "#     R_z = np.array([[np.cos(angles[2]), -np.sin(angles[2]), 0],\n",
    "#                     [np.sin(angles[2]), np.cos(angles[2]), 0],\n",
    "#                     [0, 0, 1]])\n",
    "\n",
    "#     R = np.dot(R_z, np.dot(R_y, R_x))\n",
    "\n",
    "#     # Perform rotation\n",
    "#     rotated_point = np.dot(R, point)\n",
    "\n",
    "#     # Translate point back\n",
    "#     rotated_point += center\n",
    "\n",
    "#     return rotated_point    \n",
    "    \n",
    "\n",
    "# def save_landmarks_for_slicer(points, file_path):\n",
    "\n",
    "#     # Create the header\n",
    "#     header = \"# Markups fiducial file version = 4.6\\n# CoordinateSystem = 0\\n# columns = id,x,y,z,ow,ox,oy,oz,vis,sel,lock,label,desc,associatedNodeID\\n\"\n",
    "\n",
    "#     # Create the body\n",
    "#     body = \"\\n\".join([f\"{i},{x},{y},{z},0,0,0,1,1,1,0,F{i+1},,\" for i, (x, y, z) in enumerate(points)])\n",
    "\n",
    "#     # Combine header and body\n",
    "#     fcsv_content = header + body\n",
    "\n",
    "#     # Write to file\n",
    "#     with open(file_path, \"w\") as f:\n",
    "#         f.write(fcsv_content)\n",
    "        \n",
    "# suv_0=sitk.ReadImage('/workspaces/pilot_lymphoma/data/pat_3/lin_transf/study_0_SUVS.nii.gz')\n",
    "# landmark_data=np.load('/workspaces/pilot_lymphoma/data/pat_3/lin_transf/From.npy')\n",
    "# weights=jnp.ones(6)*30\n",
    "\n",
    "# center = suv_0.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in suv_0.GetSize()])\n",
    "# center=np.array(list(center))\n",
    "# # transf_landmarsk=rotate_and_translate(landmark_data, center,weights[0:3],(weights[3:6]/10))\n",
    "# # transf_landmarsk=rotate_and_translate(landmark_data, center,[0.0,0.0,10.0],(weights[3:6]/10))\n",
    "# # transf_landmarsk=rotate_and_translate(landmark_data, center,[0.0,0.0,10.0],(weights[3:6]/10))\n",
    "# img_orig=suv_0\n",
    "\n",
    "\n",
    "\n",
    "# transf_landmarsk=list(map(lambda point : rotate_point(point, center, weights[0:3]),landmark_data))\n",
    "\n",
    "\n",
    "\n",
    "# # transf_landmarsk=transform_points_sitk(landmark_data,center,[10.0,10.0,60.0])\n",
    "# tansf_image=transform_image_sitk(img_orig,[10.0,10.0,60.0])\n",
    "# # tansf_image.SetSpacing(img_orig.GetSpacing())\n",
    "# # tansf_image.SetDirection(img_orig.GetDirection())\n",
    "# # tansf_image.SetOrigin(img_orig.GetOrigin())\n",
    "# sitk.WriteImage(tansf_image, \"/workspaces/pilot_lymphoma/data/transformed_image.nii.gz\")\n",
    "\n",
    "# # save_landmarks_for_slicer(data_dict['From'], \"/workspaces/pilot_lymphoma/data/From_from_numpy.fcsv\")\n",
    "# save_landmarks_for_slicer(transf_landmarsk, \"/workspaces/pilot_lymphoma/data/From_transformed.fcsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "import json\n",
    "import json\n",
    "json_path=\"/workspaces/pilot_lymphoma/data/pat_3/lin_transf/From.mrk.json\"\n",
    "with open(json_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "cps=data['markups'][0]['controlPoints']\n",
    "\n",
    "cps[0]['position']=[0.0,8,9]\n",
    "def numpy_rotate_point(point, center, angles):\n",
    "\n",
    "    angles=angles*(-1)\n",
    "    # Convert angles from degrees to radians\n",
    "    angles = np.radians(angles)\n",
    "\n",
    "    # Translate point back to origin\n",
    "    point -= center\n",
    "\n",
    "    # Rotation matrix\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(angles[0]), -np.sin(angles[0])],\n",
    "                    [0, np.sin(angles[0]), np.cos(angles[0])]])\n",
    "\n",
    "    R_y = np.array([[np.cos(angles[1]), 0, np.sin(angles[1])],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(angles[1]), 0, np.cos(angles[1])]])\n",
    "\n",
    "    R_z = np.array([[np.cos(angles[2]), -np.sin(angles[2]), 0],\n",
    "                    [np.sin(angles[2]), np.cos(angles[2]), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "    R = np.dot(R_z, np.dot(R_y, R_x))\n",
    "\n",
    "    # Perform rotation\n",
    "    rotated_point = np.dot(R, point)\n",
    "\n",
    "    # Translate point back\n",
    "    rotated_point += center\n",
    "\n",
    "    return rotated_point   \n",
    "\n",
    "def save_landmarks_for_slicer(points, out_file_path,original_json_path):\n",
    "    with open(original_json_path) as f:\n",
    "        data = json.load(f)\n",
    "    for i in range(len(cps)):\n",
    "        data['markups'][0]['controlPoints'][i]['position']=points[i]\n",
    "\n",
    "    with open(out_file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "    # # Create the header\n",
    "    # header = \"# Markups fiducial file version = 4.6\\n# CoordinateSystem = 0\\n# columns = id,x,y,z,ow,ox,oy,oz,vis,sel,lock,label,desc,associatedNodeID\\n\"\n",
    "\n",
    "    # # Create the body\n",
    "    # body = \"\\n\".join([f\"{i},{x},{y},{z},0,0,0,1,1,1,0,F{i+1},,\" for i, (x, y, z) in enumerate(points)])\n",
    "\n",
    "    # # Combine header and body\n",
    "    # fcsv_content = header + body\n",
    "\n",
    "    # # Write to file\n",
    "    # with open(file_path, \"w\") as f:\n",
    "    #     f.write(fcsv_content)\n",
    "\n",
    "landmarks=np.load('/workspaces/pilot_lymphoma/data/pat_3/lin_transf/From.npy')\n",
    "image=sitk.ReadImage('/workspaces/pilot_lymphoma/data/pat_3/lin_transf/study_0_SUVS.nii.gz')\n",
    "image=sitk.DICOMOrient(image,\"LPS\")\n",
    "# Assume 'image' is your image and 'landmarks' is your list of landmark points\n",
    "# weights=jnp.ones(6)*30\n",
    "weights=np.ones(6)*30\n",
    "Rotationn=Rotation.from_euler('xyz', weights[0:3], degrees=True)\n",
    "quaternion=np.array(Rotationn.as_quat())\n",
    "\n",
    "# Get the center of the image\n",
    "center = image.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in image.GetSize()])\n",
    "# center = [(index - 1) / 2.0 for index in image.GetSize()]\n",
    "\n",
    "# Create a VersorRigid3DTransform\n",
    "transform = sitk.VersorRigid3DTransform()\n",
    "transform.SetCenter(center)\n",
    "transform.SetRotation([float(quaternion[0]),float(quaternion[1]),float(quaternion[2]),float(quaternion[3])])\n",
    "\n",
    "# Resample the image\n",
    "resampler = sitk.ResampleImageFilter()\n",
    "resampler.SetOutputDirection(image.GetDirection())\n",
    "resampler.SetOutputOrigin(image.GetOrigin())\n",
    "resampler.SetOutputSpacing(image.GetSpacing())\n",
    "resampler.SetSize(image.GetSize())\n",
    "resampler.SetTransform(transform)\n",
    "resampled_image = resampler.Execute(image)\n",
    "\n",
    "\n",
    "sitk.WriteImage(resampled_image, \"/workspaces/pilot_lymphoma/data/transformed_image.nii.gz\")\n",
    "\n",
    "# rotation_matrix =np.array(Rotationn.as_matrix())\n",
    "\n",
    "rotation_matrix =np.linalg.inv(np.array(Rotationn.as_matrix()))\n",
    "resampled_landmarks= (landmarks - center) @ rotation_matrix.T + center \n",
    "resampled_landmarks=np.array(resampled_landmarks)\n",
    "resampled_landmarks=list(map(tuple,resampled_landmarks))\n",
    "\n",
    "# resampled_landmarks=list(map(lambda point : numpy_rotate_point(point, center, weights[0:3]),landmarks))\n",
    "# resampled_landmarks=list(map(tuple,resampled_landmarks))\n",
    "\n",
    "\n",
    "# affine = sitk.AffineTransform(transform.GetMatrix(), transform.GetTranslation(), transform.GetCenter())\n",
    "# # iTransform = affine.GetInverse()\n",
    "# resampled_landmarks = [affine.TransformPoint(p) for p in landmarks]\n",
    "# print(resampled_landmarks)\n",
    "\n",
    "save_landmarks_for_slicer(resampled_landmarks, \"/workspaces/pilot_lymphoma/data/From_transformed.mrk.json\",'/workspaces/pilot_lymphoma/data/pat_3/lin_transf/From.mrk.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(transform.GetMatrix())\n",
    "# rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# rotation_matrix =np.linalg.inv(np.array(Rotationn.as_matrix()))\n",
    "# resampled_landmarks= (landmarks + center) @ rotation_matrix.T - center \n",
    "# resampled_landmarks=np.array(resampled_landmarks)\n",
    "# resampled_landmarks=list(map(tuple,resampled_landmarks))\n",
    "# print(resampled_landmarks)\n",
    "# affine = sitk.AffineTransform(transform.GetMatrix(), transform.GetTranslation(), transform.GetCenter())\n",
    "# iTransform = affine.GetInverse()\n",
    "# resampled_landmarks = [iTransform.TransformPoint(p) for p in landmarks]\n",
    "# print(resampled_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# json_path=\"/workspaces/pilot_lymphoma/data/pat_3/lin_transf/From.mrk.json\"\n",
    "# with open(json_path) as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# cps=data['markups'][0]['controlPoints']\n",
    "\n",
    "# cps[0]['position']=[0.0,8,9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
