{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "from jax.scipy.spatial.transform import Rotation, Slerp\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[2., 2., 2.],\n",
       "       [2., 1., 2.],\n",
       "       [2., 3., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adapted from https://stackoverflow.com/questions/74519927/best-way-to-rotate-and-translate-a-set-of-points-in-python\n",
    "\n",
    "def rotate_and_translate(points: jnp.ndarray\n",
    "                         , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                         translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "    # rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "    rotation_matrix =Rotation.from_euler('xyz', rotation_vector, degrees=False).as_matrix()\n",
    "    return (points - center_point) @ rotation_matrix.T + center_point + translation_vector\n",
    "\n",
    "\n",
    "\n",
    "# rotateMatrix = Rotation.from_rotvec(jnp.array([ jnp.pi,0.0, 0.0])).as_matrix()\n",
    "points=jnp.array([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, -1.0, 0.0]])\n",
    "center_point=jnp.array([0.0, 0.0, 0.0])\n",
    "# newxy = (points-center_point) @ rotateMatrix.T + center_point\n",
    "\n",
    "newxy=rotate_and_translate(points, center_point, jnp.array([ jnp.pi,0.0, 0.0]), jnp.array([2.0, 2.0, 2.0]))\n",
    "newxy.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=jnp.array([1.0, 1.0, 1.0,2.0, 2.0, 2.0,3.0, 3.0, 3.0])\n",
    "weights[0:3]\n",
    "weights[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import re\n",
    "import typing\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.spatial.transform import Rotation\n",
    "import chex\n",
    "from typing import Callable, Sequence, Tuple, Union\n",
    "from dm_pix._src import augment\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "def rotate_and_translate(points: jnp.ndarray\n",
    "                         , center_point: jnp.ndarray, rotation_vector: jnp.ndarray,\n",
    "                         translation_vector: jnp.ndarray) -> jnp.ndarray:\n",
    "    # rotation_matrix = Rotation.from_rotvec(rotation_vector).as_matrix()\n",
    "\n",
    "    rotation_matrix =Rotation.from_euler('xyz', rotation_vector, degrees=True).as_matrix()\n",
    "    return (points - center_point) @ rotation_matrix.T + center_point + translation_vector\n",
    "\n",
    "\n",
    "def get_fiducial_loos(weights,from_landmarsk,to_landmarks,image_shape):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "        0-3 first rotation vector   \n",
    "        3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation\n",
    "    we apply this transformation to the fiducial points of moving image and \n",
    "    calculate the square distance between transformed fiducial points and fiducial points on fixed image           \n",
    "    \"\"\"\n",
    "    center_point=(jnp.asarray(image_shape) - 1.) / 2\n",
    "    res=rotate_and_translate(to_landmarks, center_point, weights[0:3],weights[3:6])\n",
    "    #calculate the square distance between transformed fiducial points and fiducial points on fixed image \n",
    "    return jnp.sum(((from_landmarsk-res)**2).flatten())\n",
    "    \n",
    "\n",
    "# def affine_transform(\n",
    "#     image: chex.Array,\n",
    "#     matrix: chex.Array,\n",
    "#     *,\n",
    "#     offset: Union[chex.Array, chex.Numeric] = 0.,\n",
    "#     order: int = 1,\n",
    "#     mode: str = \"constant\",\n",
    "#     cval: float = 0.0,\n",
    "# ) -> chex.Array:\n",
    "#   \"\"\"Applies an affine transformation given by matrix.\n",
    "\n",
    "#   \"\"\"\n",
    "\n",
    "#   meshgrid = jnp.meshgrid(*[jnp.arange(size) for size in image.shape],\n",
    "#                           indexing=\"ij\")\n",
    "#   indices = jnp.concatenate(\n",
    "#       [jnp.expand_dims(x, axis=-1) for x in meshgrid], axis=-1)\n",
    "\n",
    "#   zz, yy, xx = meshgrid\n",
    "#   z_center, y_center,x_center= (jnp.asarray(image.shape) - 1.) / 2.\n",
    "#   indices = jnp.array([xx - x_center, yy - y_center, zz - z_center])\n",
    "\n",
    "#   coordinates = jnp.tensordot(matrix, indices, axes=((1), (0)))\n",
    "\n",
    "#   interpolate_function = augment._get_interpolate_function(\n",
    "#       mode=mode,\n",
    "#       order=order,\n",
    "#       cval=cval,\n",
    "#   )\n",
    "#   return interpolate_function(image, coordinates)\n",
    "\n",
    "\n",
    "    \n",
    "def transform_image(image,weights):\n",
    "    \"\"\"\n",
    "    first entries in in weights are :\n",
    "    0-3 first rotation vector   \n",
    "    3-6 translation vector   \n",
    "    so we interpret the weights as input for transormations rotation;translation;rotation\n",
    "    \"\"\"      \n",
    "    quaternion=np.array(Rotation.from_euler('xyz', weights[0:3], degrees=True).as_quat())\n",
    "    # image_path=\"/root/data/pat_2/general_transform//study_0_ct_soft.nii.gz\"\n",
    "    # image_path_b=\"/workspaces/pilot_lymphoma/data/rotated.nii.gz\"\n",
    "\n",
    "\n",
    "    # Load the image\n",
    "    image = sitk.GetImageFromArray(image)\n",
    "\n",
    "    # Get the center of the image\n",
    "    center = image.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in image.GetSize()])\n",
    "\n",
    "    # Create a VersorRigid3DTransform\n",
    "    transform = sitk.VersorRigid3DTransform()\n",
    "    transform.SetCenter(center)\n",
    "    transform.SetRotation([float(quaternion[0]),float(quaternion[1]),float(quaternion[2]),float(quaternion[3])])\n",
    "\n",
    "    # Resample the image\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputDirection(image.GetDirection())\n",
    "    resampler.SetOutputOrigin(image.GetOrigin())\n",
    "    resampler.SetOutputSpacing(image.GetSpacing())\n",
    "    resampler.SetSize(image.GetSize())\n",
    "    resampler.SetTransform(transform)\n",
    "\n",
    "    resampled_image = resampler.Execute(image)\n",
    "    res=sitk.GetArrayFromImage(resampled_image)\n",
    "    # image=affine_transform(image,Rotation.from_euler('xyz', weights[0:3], degrees=True).inv().as_matrix())\n",
    "    image=jnp.array(res)\n",
    "    res=jax.image.scale_and_translate(image, image.shape,jnp.array([0,1,2]), jnp.array([1.0,1.0,1.0]), (weights[3:6]/20), \"bicubic\")\n",
    "    return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_0': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'study_1': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " 'From': Array([[   -9.490384 ,   201.9817   ,  -434.5      ],\n",
       "        [  -10.825081 ,   223.7493   ,  -537.2692   ],\n",
       "        [   -2.6794205,   136.67894  ,  -907.3182   ],\n",
       "        [  -42.204777 ,   143.36389  , -1004.6995   ],\n",
       "        [   49.448223 ,   139.29106  , -1010.4278   ]], dtype=float32),\n",
       " 'To': Array([[-1.5628610e+01,  2.2513477e+02, -1.0745000e+03],\n",
       "        [-1.2932510e+01,  2.3373933e+02, -1.2070104e+03],\n",
       "        [-7.1401978e-01,  1.3851543e+02, -1.5706969e+03],\n",
       "        [-3.9721409e+01,  1.5480675e+02, -1.6590372e+03],\n",
       "        [ 4.5177025e+01,  1.5073392e+02, -1.6750990e+03]], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def resample_ct_to_suv(ct: sitk.Image, suv: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Resample a CT image to the same size as a SUV image\n",
    "    \"\"\"\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "    resampler.SetOutputSpacing(suv.GetSpacing())\n",
    "    resampler.SetSize(suv.GetSize())\n",
    "    resampler.SetOutputDirection(suv.GetDirection())\n",
    "    resampler.SetOutputOrigin(suv.GetOrigin())\n",
    "    ct= resampler.Execute(ct)\n",
    "    \n",
    "    ct_arr=sitk.GetArrayFromImage(ct)\n",
    "    suv_arr=sitk.GetArrayFromImage(suv)\n",
    "    \n",
    "    res=jnp.stack([jnp.array(suv_arr),jnp.array(ct_arr)],axis=0)\n",
    "    return res\n",
    "\n",
    "def load_landmark_data(folder_path:str):\n",
    "    \"\"\"\n",
    "    given path to folder with landmarks files and images after general registaration we load the data\n",
    "    we want to first load the suv and ct images resample them to the same size and then load the landmarks\n",
    "    we need to load separately study 0 and 1 \n",
    "    the output should be in form of a dictionary with keys 'study_0','study_1','From`,`To`' where `From` and `To` are the landmarks\n",
    "    all the data should be in form of jnp.arrays\n",
    "    \"\"\"\n",
    "    ct_0=sitk.ReadImage(folder_path+'/study_0_ct_soft.nii.gz')\n",
    "    suv_0=sitk.ReadImage(folder_path+'/study_0_SUVS.nii.gz')\n",
    "    # Resample ct_0 to match ct_1\n",
    "    arr_0 = resample_ct_to_suv(ct_0, suv_0)\n",
    "            \n",
    "    ct_1=sitk.ReadImage(folder_path+'/study_1_ct_soft.nii.gz')\n",
    "    suv_1=sitk.ReadImage(folder_path+'/study_1_SUVS.nii.gz')    \n",
    "    arr_1 = resample_ct_to_suv(ct_1, suv_1)\n",
    "\n",
    "    return {'study_0':arr_0,'study_1':arr_1, 'From':jnp.load(folder_path+'/From.npy'),'To':jnp.load(folder_path+'/To.npy')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path='/root/data/pat_2/general_transform'\n",
    "load_landmark_data(folder_path)\n",
    "\n",
    "# cp /root/data/pat_2/To.npy /root/data/pat_2/general_transform/To.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_dat (2, 425, 200, 200) landmark_data (5, 3) weights (6,)\n",
      " landmark_data (5, 3) center_point [  0.5 212.   99.5] weights (6,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "folder_path = \"/root/data\"\n",
    "folder_names = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "folder_names=list(filter(lambda x: re.match(r'pat_\\d+',x),folder_names))\n",
    "folder_names=list(map(lambda x: f\"{folder_path}/{x}/general_transform\",folder_names))\n",
    "\n",
    "curr_folder='/root/data/pat_2/general_transform'\n",
    "data_dict=load_landmark_data(curr_folder)\n",
    "\n",
    "# v_transform_image=jax.vmap(transform_image , in_axes = (0,None) )\n",
    "\n",
    "def get_data_for_pretained_model(image_dat,landmark_data, rng):\n",
    "    \"\"\"\n",
    "    given the image data and landmark data we return the data in the format that can be used for the pretrained model\n",
    "    so we make a random transformation of the image and the landmarks and return the transformed image and landmarks \n",
    "    \"\"\"\n",
    "    #random weights for the transformation\n",
    "    weights = jax.random.uniform(rng, shape=(6,), minval=0, maxval=360)\n",
    "    # print(f\"image_dat {image_dat.shape} landmark_data {landmark_data.shape} weights {weights.shape}\")\n",
    "    tansf_image=jnp.stack([transform_image(image_dat[0,:,:,:],weights),transform_image(image_dat[1,:,:,:],weights)   ])\n",
    "    center_point=(jnp.asarray(image_dat.shape) - 1.) / 2\n",
    "    center_point=center_point[0:3]\n",
    "    # print(f\" landmark_data {landmark_data.shape} center_point {center_point} weights {weights.shape}\")\n",
    "    transf_landmarsk=rotate_and_translate(landmark_data, center_point,weights[0:3],(weights[3:6]/10))\n",
    "\n",
    "\n",
    "    return tansf_image,transf_landmarsk\n",
    "\n",
    "# krowa transform the image save it and check if it tranforms correctly\n",
    " \n",
    "\n",
    "random_seed = 42\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "tansf_image,transf_landmarsk=get_data_for_pretained_model(data_dict['study_0'],data_dict['From'], rng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder_path=\"/workspaces/pilot_lymphoma/data\"\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `transf_image` and `data_dict['study_0']` are JAX arrays\n",
    "transf_image_np = np.array(tansf_image[0,:,:,:])\n",
    "study_0_np = np.array(data_dict['study_0'][0,:,:,:])\n",
    "\n",
    "# Create SimpleITK images\n",
    "transf_image_sitk = sitk.GetImageFromArray(transf_image_np)\n",
    "study_0_sitk = sitk.GetImageFromArray(study_0_np)\n",
    "\n",
    "# Save as NIfTI files\n",
    "sitk.WriteImage(transf_image_sitk, '/workspaces/pilot_lymphoma/data/transf_image.nii.gz')\n",
    "sitk.WriteImage(study_0_sitk, '/workspaces/pilot_lymphoma/data/study_0.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_landmarks_for_slicer(points, file_path):\n",
    "\n",
    "    # Create the header\n",
    "    header = \"# Markups fiducial file version = 4.6\\n# CoordinateSystem = 0\\n# columns = id,x,y,z,ow,ox,oy,oz,vis,sel,lock,label,desc,associatedNodeID\\n\"\n",
    "\n",
    "    # Create the body\n",
    "    body = \"\\n\".join([f\"{i},{x},{y},{z},0,0,0,1,1,1,0,F{i+1},,\" for i, (x, y, z) in enumerate(points)])\n",
    "\n",
    "    # Combine header and body\n",
    "    fcsv_content = header + body\n",
    "\n",
    "    # Write to file\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(fcsv_content)\n",
    "        \n",
    "ct_0=sitk.ReadImage(folder_path+'/study_0_ct_soft.nii.gz')\n",
    "From=jnp.load(folder_path+'/From.npy')\n",
    "transf_landmarsk=rotate_and_translate(landmark_data, center_point,weights[0:3],(weights[3:6]/10))\n",
    " \n",
    "save_landmarks_for_slicer(data_dict['From'], \"/workspaces/pilot_lymphoma/data/From.fcsv\")\n",
    "save_landmarks_for_slicer(transf_landmarsk, \"/workspaces/pilot_lymphoma/data/From_transformed.fcsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = jax.scipy.spatial.transform.Rotation.from_rotvec(jnp.array([jnp.pi,jnp.pi, jnp.pi])) ####### it is in radians\n",
    "# quaternion=np.array(r.as_quat())\n",
    "# image_path=\"/root/data/pat_2/general_transform//study_0_ct_soft.nii.gz\"\n",
    "# image_path_b=\"/workspaces/pilot_lymphoma/data/rotated.nii.gz\"\n",
    "\n",
    "# import SimpleITK as sitk\n",
    "\n",
    "# # Load the image\n",
    "# image = sitk.ReadImage(image_path)\n",
    "\n",
    "# # Get the center of the image\n",
    "# center = image.TransformContinuousIndexToPhysicalPoint([(index - 1) / 2.0 for index in image.GetSize()])\n",
    "\n",
    "# # Create a VersorRigid3DTransform\n",
    "# transform = sitk.VersorRigid3DTransform()\n",
    "# transform.SetCenter(center)\n",
    "# transform.SetRotation([float(quaternion[0]),float(quaternion[1]),float(quaternion[2]),float(quaternion[3])])\n",
    "\n",
    "# # Resample the image\n",
    "# resampler = sitk.ResampleImageFilter()\n",
    "# resampler.SetOutputDirection(image.GetDirection())\n",
    "# resampler.SetOutputOrigin(image.GetOrigin())\n",
    "# resampler.SetOutputSpacing(image.GetSpacing())\n",
    "# resampler.SetSize(image.GetSize())\n",
    "# resampler.SetTransform(transform)\n",
    "\n",
    "# resampled_image = resampler.Execute(image)\n",
    "\n",
    "# # Save the resampled image\n",
    "# sitk.WriteImage(resampled_image, image_path_b)\n",
    "# # saver.save(rotated_image, image_path_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
